{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae7ca67-267f-4de8-ab9a-8d0aad19b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader  # 将数据集返回拼接成一个batch提供多线程优化和数据置乱等操作。\n",
    "import torchvision.datasets as ds  # 已有的一些数据训练数据库\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72cc7a8-0eaa-46af-9f42-827cedb7ff9c",
   "metadata": {},
   "source": [
    "# 1. 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bcf3dd-c482-48d9-aa90-547ab2abdc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds.MNIST(root='./',   # 选择数据的根目录 \n",
    "                         train=True,      # 作为训练集\n",
    "                         transform = transforms.ToTensor(),  # 转换成Tensor \n",
    "                         download = False)  # 未下载数据时设定未True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf5f1a9-1ee0-4c4c-9a7e-18e951432fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ds.MNIST(root = './',\n",
    "                        train = False,   # 作为测试集\n",
    "                        transform = transforms.ToTensor(),\n",
    "                        download = False)  # 未下载数据时设定未True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24321cc-8268-4f59-a323-761b28514db0",
   "metadata": {},
   "source": [
    "查看数据集 <br>\n",
    "训练集包含60 000个样本，测试集包含10 000个样本。<br>\n",
    "每张图像尺寸均是 28x28 像素，目标变量为 0-9 的标签 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "107a153f-a331-4c7d-89a3-5fed4d081ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset= torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset=\", train_dataset.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6962cd9f-8797-4a57-8db6-2166a9eca824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels= torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(\"train_labels=\", train_dataset.targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340888cb-c24d-451a-bd1c-15bb31bc7dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data= torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"test_data=\", test_dataset.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c7e472-c0a6-46ab-bcc1-4b6d48617b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_labels= torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(\"test_labels=\", test_dataset.targets.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f54e0-339d-473c-bf12-0e043e57f445",
   "metadata": {},
   "source": [
    "# 2.数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf047102-2221-413b-a644-f9c1f5de2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abc1f4c2-cee5-4229-b00f-f7ad3945b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size ,\n",
    "    shuffle = True   # 将数据置乱\n",
    ")\n",
    "\n",
    "# 加载测试数据\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4136b7-925d-40ee-8170-458ea81ae8b6",
   "metadata": {},
   "source": [
    "图像绘制查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c62a2ed-dff6-411d-9b7f-f6eab58ae93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = train_loader.dataset.data[1]\n",
    "plt.imshow(digit,cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "print(train_loader.dataset.targets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e35f5-9379-4362-a708-6ba80611c51d",
   "metadata": {},
   "source": [
    "# 3. 定义神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c073c-afd7-45ec-bfd6-203f11f60482",
   "metadata": {},
   "source": [
    "定义一个简单的神经网络，继承pytorch中的Module,重写forward()函数完成前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02d72d87-aaeb-41d5-a5dd-e8b1bfe5a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nerual_net(\n",
      "  (layer1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (layer2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "input_size = 784   # MNIST中的图像尺寸为 28*28\n",
    "hidden_size = 500  # 隐藏层数量\n",
    "num_classes = 10   # 输出数字 0-9, 共10个类别\n",
    "\n",
    "# 创建网络模型\n",
    "class Nerual_net(nn.Module):\n",
    "    def __init__(self, input_num, hidden_size, out_put):  # 初始化操作\n",
    "        super(Nerual_net, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_num, hidden_size) \n",
    "        self.layer2 = nn.Linear(hidden_size, out_put)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)   # 输入层到隐藏层\n",
    "        # print(\"out=\",out)\n",
    "        out = torch.relu(out)  # 采用ReLU激活函数\n",
    "        out = self.layer2(out) # 隐藏层到输出层\n",
    "        return out\n",
    "\n",
    "net = Nerual_net(input_size, hidden_size, num_classes)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b1484-6084-474d-b598-5e41e02c9b9e",
   "metadata": {},
   "source": [
    "# 4.网络训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6855fd76-a698-4eb9-a48f-49cb85e30180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current eponch = 0\n",
      "current loss=2.32050\n",
      "current eponch = 1\n",
      "current loss=1.40199\n",
      "current eponch = 2\n",
      "current loss=0.82275\n",
      "current eponch = 3\n",
      "current loss=0.58162\n",
      "current eponch = 4\n",
      "current loss=0.52284\n",
      "current eponch = 5\n",
      "current loss=0.44654\n",
      "current eponch = 6\n",
      "current loss=0.39353\n",
      "current eponch = 7\n",
      "current loss=0.39206\n",
      "current eponch = 8\n",
      "current loss=0.35534\n",
      "current eponch = 9\n",
      "current loss=0.34799\n",
      "current eponch = 10\n",
      "current loss=0.31988\n",
      "current eponch = 11\n",
      "current loss=0.33459\n",
      "current eponch = 12\n",
      "current loss=0.31788\n",
      "current eponch = 13\n",
      "current loss=0.37732\n",
      "current eponch = 14\n",
      "current loss=0.28604\n",
      "current eponch = 15\n",
      "current loss=0.30304\n",
      "current eponch = 16\n",
      "current loss=0.31805\n",
      "current eponch = 17\n",
      "current loss=0.32884\n",
      "current eponch = 18\n",
      "current loss=0.29485\n",
      "current eponch = 19\n",
      "current loss=0.30398\n",
      "current eponch = 20\n",
      "current loss=0.29349\n",
      "current eponch = 21\n",
      "current loss=0.30264\n",
      "current eponch = 22\n",
      "current loss=0.30105\n",
      "current eponch = 23\n",
      "current loss=0.25560\n",
      "current eponch = 24\n",
      "current loss=0.25524\n",
      "current eponch = 25\n",
      "current loss=0.24490\n",
      "current eponch = 26\n",
      "current loss=0.27280\n",
      "current eponch = 27\n",
      "current loss=0.25748\n",
      "current eponch = 28\n",
      "current loss=0.20535\n",
      "current eponch = 29\n",
      "current loss=0.28020\n",
      "current eponch = 30\n",
      "current loss=0.25039\n",
      "current eponch = 31\n",
      "current loss=0.23075\n",
      "current eponch = 32\n",
      "current loss=0.25090\n",
      "current eponch = 33\n",
      "current loss=0.22432\n",
      "current eponch = 34\n",
      "current loss=0.20550\n",
      "current eponch = 35\n",
      "current loss=0.20083\n",
      "current eponch = 36\n",
      "current loss=0.22883\n",
      "current eponch = 37\n",
      "current loss=0.20625\n",
      "current eponch = 38\n",
      "current loss=0.25073\n",
      "current eponch = 39\n",
      "current loss=0.23462\n",
      "current eponch = 40\n",
      "current loss=0.26558\n",
      "current eponch = 41\n",
      "current loss=0.23702\n",
      "current eponch = 42\n",
      "current loss=0.18607\n",
      "current eponch = 43\n",
      "current loss=0.21899\n",
      "current eponch = 44\n",
      "current loss=0.18163\n",
      "current eponch = 45\n",
      "current loss=0.21486\n",
      "current eponch = 46\n",
      "current loss=0.20756\n",
      "current eponch = 47\n",
      "current loss=0.19935\n",
      "current eponch = 48\n",
      "current loss=0.21239\n",
      "current eponch = 49\n",
      "current loss=0.17140\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-2  # 学习率设置为0.05\n",
    "num_epoches = 50   # 训练论述设为50\n",
    "criterion = nn.CrossEntropyLoss()  # 采用交叉熵损失函数\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = learning_rate)   # 梯度下降\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    print('current eponch = %d'% epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 28*28)\n",
    "        outputs = net(images)   # 将数据集传入网络, 进行前向计算。\n",
    "        loss = criterion(outputs, labels)  # 计算损失函数值\n",
    "        optimizer.zero_grad()  # 反向传播前需要清楚网络状态\n",
    "        loss.backward()   # 误差反向传播\n",
    "        optimizer.step()   # 更新模型参数\n",
    "        if i % 100 == 0:\n",
    "            print('current loss=%.5f' % loss.item())\n",
    "print('finished training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c1698-aa3a-48ff-a53c-11fcbed8402b",
   "metadata": {},
   "source": [
    "# 5. 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80b856be-f524-45a1-af13-242d0e5ce7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=10.26\n",
      "total_num= 10000 , correct_num= tensor(1026)\n"
     ]
    }
   ],
   "source": [
    "total_num = 0\n",
    "correct_num = 0\n",
    "\n",
    "for images, label in test_loader:\n",
    "    images = images.view(-1, 28*28)\n",
    "    outputs = net(images)\n",
    "    _, predicts = torch.max(outputs.data, 1)  # _：最大值本身, predicts：最大值对应的索引（即预测的类别标签）\n",
    "    total_num += labels.size(0)\n",
    "    correct_num += (predicts == labels).sum()\n",
    "    \n",
    "print(\"Accuracy=%.2f\" % (100*correct_num/total_num))\n",
    "print(\"total_num=\",total_num, \", correct_num=\", correct_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05607cce-bc44-4d04-95c3-406e8fe71cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
